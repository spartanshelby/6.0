new jsurl
1)get all url from burpproject of target scope
2)remove duplicates & save it into file 
3)open browser check first session expires or not 
4)then create a temporary project with burp and turn intercept on 
5)open custom script firefox_openurls https://github.com/tabwrangler/tabwrangler/ extension to load all urls (auto close)
6)find new js by compare with old one  
7)copy the new js urls and remove all scopes and paste all urls to scope (jslinkfinder find 3rd 4th level js)
8)then only select new js and collect new endpoints,parameters 


grep -Fxv -f fileold filenew
Outputs only URLs that are in filenew but NOT in fileold


answer: In the video context, he's likely encountering BOTH patterns - sometimes the same JS file gets new code (Pattern A), and sometimes completely new JS files appear (Pattern B). 
The key is to monitor for any changes because new code = new attack surface, regardless of whether it's in an existing file or a new one.

exsisting but code updated js 
1)browse and capture request using bp
2)go to tar tab seach .js with inscope only 
3)if the .js file present in html as dynamic then use gap to find all js urls from .html files 
  otherwise directly turn on jslinkfinder and run passive scan will give all other jsurls from jslinfider.
4)find which subdomain or url contains all endpoints that related to tar websites.  use this https://www.netify.ai/resources/domains/target.com to find easypeasy
5)then waybacurls & other to collect all possible urls
6)run all new js to bp and find new endpoints using gap & jslinkfinder
7)monitor those js urls using jsmon


remove unwanted js
grep -v -i -E '(jquery|bootstrap|react|googleapis|cloudflare|gtm|analytics|facebook|twitter|fontawesome|jquery|bootstrap|react|vue|angular|moment|lodash|jquery|bootstrap|popper|lodash|moment|axios|react|vue|angular|zone|firebase|chart|d3|fontawesome|polyfill|runtime|vendors|vendor|common|app|manifest|inline|service-worker|gtag|analytics|googletagmanager|google-analytics|googlesyndication|hotjar|sentry|unpkg)' js.txt > filteredjs.txt



remove domain
cat burp_slash_something.txt | awk '{gsub("https://example.com", "")}1' > endpointss.txt

unique way to grep jslinkfinder output to endpoint  
cat yourapire.txt | awk '{print $4}'  | grep /app/ | sort -u > #/endpoints.txt

match burp endpoint with jslinkfinders
# Print matched endpoints (present in both files)
grep -Fxf file1.txt file2.txt > match_same_url_sorted_url.txt

# Print endpoints in file1.txt that are NOT in file2.txt
grep -Fvxf file1.txt file2.txt

if wont work in intruder then dont fuzz endpoint instead openmultipleurls - cat uniquendpoints.txt | awk '{print "https:/example.com" $0}' > newurlsuniquendpoints4multipleurls.txt

